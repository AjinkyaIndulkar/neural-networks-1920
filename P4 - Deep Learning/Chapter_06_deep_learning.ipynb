{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Author contributions\n",
    "Please fill out for each of the following parts who contributed to what:\n",
    "- Conceived ideas: \n",
    "- Performed math exercises: - (there are no math exercises this time)\n",
    "- Performed programming exercises:\n",
    "- Contributed to the overall final assignment: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6\n",
    "## Deep learning\n",
    "\n",
    "\n",
    "    Hand-in bug-free (try \"Kernel\" > \"Restart & Run All\") and including all (textual as well as figural) output via Brightspace before the deadline (see Brightspace).\n",
    "\n",
    "Learning goals:\n",
    "1. Get familiar with a state-of-the-art module for deep learning\n",
    "1. Implement and run a multilayer neural network in PyTorch\n",
    "1. Understand convolution\n",
    "1. Implement and run a convolutional neural network in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal as ss\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might occur that the above imports throw an error, saying `torch` is an unknown module. If so, you have not yet installed `pytorch` properly. Do so by opening a terminal and installing it by calling `conda install pytorch torchvision -c pytorch` (i.e., see https://pytorch.org/get-started/locally/).\n",
    "\n",
    "When working on a state-of-the-art neural network project you will rely on one of the various neural network frameworks that are available, instead of implementing core functionality by yourself. In this exercise you will work on implementing an MLP and a CNN in the PyTorch framework. \n",
    "\n",
    "To get familiar with PyTorch, read the tutorial at https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html. It is a good introduction to PyTorch including setting up data, defining a model, and training a model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: MNIST data (1 point)\n",
    "We will use the MNIST dataset (handwritten digets) for this assignment. The dataset is a very standard and commonly used benchmark dataset. In this assignment, we will only work with a training and validation dataset. Normally, one would also have a testing dataset, but we will ignore this in this assignment.\n",
    "1. Load the *MNIST* dataset. Use a training and a validation dataset.\n",
    "1. Define training and validation data iterators and use a specific batchsize.\n",
    "1. Inspect the training and validation data by printing (1) the amount of samples in each set and (2) the shape of a data sample.\n",
    "1. Inspect the training and validation data by plotting some samples (as images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#input_size = 784\n",
    "#hidden_size = 500\n",
    "#num_classes = 10\n",
    "#num_epochs = 5\n",
    "batch_size = 100\n",
    "#learning_rate = 0.001\n",
    "\n",
    "# 1.\n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data', train=True, transform=transforms.ToTensor(), download = True)\n",
    "val_dataset = torchvision.datasets.MNIST(root='../../data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# 2.\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset = val_dataset, batch_size = batch_size, shuffle=False)\n",
    "\n",
    "# 3. \n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(example_data.shape)\n",
    "\n",
    "examples = enumerate(val_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(example_data.shape)\n",
    "\n",
    "\n",
    "# 4.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Training a model (3 points)\n",
    "Define a function `train_model` with input arguments `model`, `train_data`, `valid_data`, `optimizer`, `criterion`, and `n_epochs`, and output arguments `model`, `train_loss`, `valid_loss`, `train_accuracy`, `valid_accuracy`. We will use this function to train both a MLP as well as a CNN. It therefore has to be generic to any type of model, optimizer, or loss function. The function:\n",
    "1. Loops over `n_epoch` epochs.\n",
    "1. Loops over minibatches of both training data `train_data` as well as validation data `valid_data`.\n",
    "1. Trains the model using the loss function defined by `criterion` and optimizer `optimizer` using the training data.\n",
    "1. Computes and saves losses for both training and validation data per epoch in `train_loss` and `valid_loss`.\n",
    "1. Computes and saves accuracies for both training and validation data per epoch in `train_accuracy` and `valid_accuracy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, valid_data, optimizer, criterion, n_epochs):\n",
    "    \n",
    "    train_loss = np.zeros(n_epochs)\n",
    "    valid_loss = np.zeros(n_epochs)\n",
    "    train_accuracy = np.zeros(n_epochs)\n",
    "    valid_accuracy = np.zeros(n_epochs)\n",
    "    \n",
    "    for epoch in range (n_epochs):\n",
    "        \n",
    "        for i, (images, labels) in (train_data):\n",
    "            images = images.reshape(-1, 28*28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            train_loss[epoch] = criterion(outputs, labels)\n",
    "            \n",
    "            train_accuracy[epoch] = (outputs == labels).sum()/images.size\n",
    "                        \n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        for i, (images, labels) in (valid_data):\n",
    "            images = images.reshape(-1, 28*28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            valid_loss[epoch] = criterion(outputs, labels)\n",
    "            \n",
    "            valid_accuracy[epoch] = (outputs == labels).sum()/images.size\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            valid_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "    return model, train_loss, valid_loss, train_accuracy, valid_accuracy      \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Setup an MLP (1 point)\n",
    "As a first model, setup a multilayer perceptron:\n",
    "1. with two linear (i.e., fully connected) weight layers\n",
    "1. with a hidden layer of 16 ReLU units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Train the MLP (1 point) \n",
    "Train the MLP using the MNIST dataset:\n",
    "1. As optimizer use SGD with a learning rate of 0.001 and momentum of 0.9.\n",
    "1. As loss function use the cross-entropy loss.\n",
    "1. Train the MLP in 20 epochs.\n",
    "1. Plot the training and validation losses as a function of epochs.\n",
    "1. Plot the training and validation accuracies as a function of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Visualize the weights (0.5 points)\n",
    "The model's weights in a particular layer that the MLP has learned can be found in `model_name.layer_name.weight.data`. Plot the weights of the 16 ReLU units as 2D images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: Convolution with hand-made kernels (1 point)\n",
    "In convolutional neural networks we use a mathematical operator between two functions $f$ and $g$ called [*convolution*](https://en.wikipedia.org/wiki/Convolution). In terms of images, one could intuitively think of $f$ as an image, and $g$ as a filter kernel (i.e., a receptive field). For images we need to use 2D convolution: \n",
    "\n",
    "$$f(x, y) \\ast g(x, y) = \\sum^N_{i=-N}\\sum^N_{j=-N} f(x, y)g(x-i, y-j)$$\n",
    "\n",
    "Intuitively, the kernel $g$ is applied on all spatial locations of $f$. You could think of $g$ as having weights that represent how it singles out local input. Usually there are various of these filter kernels $g$, scanning the image for many possible features. \n",
    "\n",
    "In this exercise you will perform a simple convolution on one image.\n",
    "1. Make four $3 \\times 3$ kernels. They should represent horizontal, vertical, and the two diagonal line feature detectors.\n",
    "1. Plot these kernels.\n",
    "1. Apply the kernels to the image, e.g. by using `convolved2d` from `scipy`.\n",
    "1. Plot the resulting feature activity map for each of the kernels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The image\n",
    "image = train[2][0].reshape((28, 28))\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "ax.imshow(image, cmap=\"gray\")\n",
    "ax.set_xticks([], []) ; ax.set_yticks([], [])\n",
    "\n",
    "# 1. Create kernels\n",
    "kernel_template = [ [-1.0, -1.0, -1.0], \n",
    "                    [-1.0,  2.0, -1.0], \n",
    "                    [-1.0, -1.0, -1.0] ]   # example: point detector\n",
    "## Code here ##\n",
    "\n",
    "# 2. Plot kernels\n",
    "## Code here ##\n",
    "\n",
    "# 3. Convolve the image with the kernels\n",
    "## Code here ##\n",
    "\n",
    "# 4. Plot the activity maps\n",
    "## Code here ##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise 7: Setup a CNN (1 points)\n",
    "As a second model, setup a CNN with:\n",
    "1. One convolutional layer and one linear (i.e., fully connected) weight layer.\n",
    "1. In the convolutional layer, use $8$ kernels of size $3\\times3$ and stride $1$.\n",
    "1. ReLU units in the hidden layer.\n",
    "1. Max pooling with kernels of size $2\\times2$ and stride $2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8: Train the CNN (1 point) \n",
    "Train the CNN using the MNIST dataset:\n",
    "1. As optimizer use SGD with a learning rate of 0.001 and momentum of 0.9.\n",
    "1. As loss function use the cross-entropy loss.\n",
    "1. Train the CNN in 20 epochs.\n",
    "1. Plot the training and validation losses as a function of epochs.\n",
    "1. Plot the training and validation accuracies as a function of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9: Visualize the weights (0.5 points)\n",
    "The model's weights in the convolutional layer that the CNN has learned can be found in `model_name.layer_name.weight.data`. Plot the kernels as images.\n",
    "\n",
    "Showing what the first weight layer learns is easy. But this task becomes more difficult in higher layers, and is a current area of research. Here is highly recommended reading on what convolutional neural networks learn: \n",
    "\n",
    "[Feature visualization: How neural networks build up their understanding of images](https://distill.pub/2017/feature-visualization/)\n",
    "\n",
    "[The building blocks of interpretability](https://distill.pub/2018/building-blocks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10: Interpretation (2 points)\n",
    "1. Which of the two models performed better for classifying MNIST digits in this example? Compare speed of training and test set accuracy. \n",
    "1. The main difference of the models is the type of the first layer. Why would a convolutional layer lead to the better succes here? \n",
    "1. Explain one argument why the convolution operation is biologically plausible and one argument why it is biologically implausible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Solution 10\n",
    "1. Answer here.\n",
    "1. Answer here.\n",
    "1. Answer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
